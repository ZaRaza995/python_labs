def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if text is None:
        raise ValueError("ĞÑˆĞ¸Ğ±ĞºĞ°: Ñ‚ĞµĞºÑÑ‚ Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ None")
    if not isinstance(text, str):
        raise TypeError(f"ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ»Ğ°ÑÑŒ ÑÑ‚Ñ€Ğ¾ĞºĞ°, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ {type(text).__name__}")
    if len(text) == 0:
        return ""
    if yo2e:
        text = text.replace('Ñ‘', 'Ğµ').replace('Ğ', 'Ğ•')
    if casefold:
        text = text.casefold()
    return ' '.join(text.split())
print(normalize("ĞŸÑ€Ğ˜Ğ²Ğ•Ñ‚\nĞœĞ˜Ñ€\t"))       
print(normalize("Ñ‘Ğ¶Ğ¸Ğº, ĞĞ»ĞºĞ°"))      
print(normalize("Hello\r\nWorld"))     
print(normalize( "  Ğ´Ğ²Ğ¾Ğ¹Ğ½Ñ‹Ğµ   Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹  "))


import re   
def tokenize(text: str) -> list[str]:
    return re.findall(r"\w+(?:-\w+)*", text)

print(tokenize("Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€"))
print(tokenize("hello,world!!!"))
print(tokenize("Ğ¿Ğ¾-Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰ĞµĞ¼Ñƒ ĞºÑ€ÑƒÑ‚Ğ¾"))
print(tokenize("2025 Ğ³Ğ¾Ğ´"))
print(tokenize("emoji ğŸ˜€ Ğ½Ğµ ÑĞ»Ğ¾Ğ²Ğ¾"))


def count_freq_manual(tokens: list[str]) -> dict[str, int]:
    if not tokens:
        return {}
    freq_dict = {}
    for token in tokens:
        freq_dict[token] = freq_dict.get(token, 0) + 1
    return freq_dict
print(count_freq_manual(["a","b","a","c","b","a"]))
print(count_freq_manual(["bb","aa","bb","aa","cc"]))

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    sorted_items = sorted(freq.items(), key=lambda item: (-item[1], item[0]))
    return sorted_items[:n]